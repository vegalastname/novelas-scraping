import requests
from bs4 import BeautifulSoup
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Descargar recursos NLTK (necesario en Docker)
nltk.download('punkt')
nltk.download('stopwords')

# Web scraping
url = "https://www.gutenberg.org/files/2701/2701-0.txt"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
text = soup.get_text()

# Preprocesar
tokens = word_tokenize(text.lower())
stop_words = set(stopwords.words('english'))
clean_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]

# Frecuencia
word_freq = Counter(clean_tokens)

# Nube de palabras
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(word_freq))
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.savefig('/output/wordcloud.png')  # Guardar en volumen montado
plt.close()  # Cerrar figura para no mostrar en contenedor sin GUI
print("An√°lisis completado. Nube de palabras guardada en /output/wordcloud.png")
